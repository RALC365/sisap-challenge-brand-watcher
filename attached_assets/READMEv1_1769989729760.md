# The AI Machine

## AI‑First Delivery Process for the Brand Protection Monitor (PoC)

**Context:** Full Stack Engineering Challenge — Brand Protection Monitor (PoC)

**Challenge Owner:** SISAP (Recruitment Process)

**Candidate:** Richardson Cárcamo

---

## 1. Purpose of This Document

This document describes **"The AI Machine"**, an **AI‑first engineering process** used to design and implement the *Brand Protection Monitor (PoC)* required by the SISAP Tech Challenge.

The goal of this documentation is to:

- Explicitly document **how AI was used**, as allowed and encouraged by the challenge.
- Explain **each GPT agent involved**, its objective, inputs, and outputs.
- Describe the **technical and architectural decisions** taken along the way, including trade‑offs and rationale.
- Demonstrate **ownership, understanding, and human validation** of all AI‑generated artifacts.

This document is intended to complement the source code and the generated PDFs, and to satisfy the **“Communication”** and **“Design Decisions / Ambiguities”** evaluation criteria of the challenge.

---

## 2. Alignment with the Tech Challenge Requirements

The *Tech Challenge* explicitly states that:

- **AI usage is permitted and encouraged**.
- The candidate must **understand, validate, and explain** any AI‑generated output.
- A detailed `README.md` describing **design decisions, trade‑offs, and limitations** is required.

> This process was intentionally designed to exceed those expectations by making AI usage **explicit, structured, auditable, and human‑validated**.

---

## 3. The AI Machine — High‑Level Overview

**The AI Machine** is an **AI‑first, human‑validated delivery pipeline**.

Core principles:

1. **AI as the primary generator** of specifications, schemas, and architecture.
2. **Human oversight at every boundary** (validation, corrections, constraints).
3. **Single‑source‑of‑truth documents** produced per domain.
4. **Zero ambiguity tolerance** — all assumptions must be resolved explicitly.

### Conceptual Flow

```
Problem Definition (Tech Challenge)
        ↓
Context Normalization (AI)
        ↓
Domain‑Specific GPT Agents
        ↓
Formal Source‑of‑Truth Documents (PDF)
        ↓
Human Review & Constraint Enforcement
        ↓
Code Generation (Replit)
        ↓
Final PoC
```

---

## 4. GPT Agents Used in the Process

The AI Machine was executed through **a strict, sequential chain of specialized GPT agents**. Each GPT consumes the validated output of the previous one. Skipping or reordering agents is explicitly forbidden in this process.

The **exact execution order** is the following:

```
1. Normalizer
2. PRD
3. User Stories
4A. UX/UI
4B. Database
5A. Tech Lead
5B. Infra
6. Prompt Generator
```

Each GPT has a **non-overlapping responsibility**, clear inputs, and a concrete output artifact (PDF or prompt set).

---

### 4.1 GPT 1 — Normalizer

**Objective:**

Normalize and lock the problem space before any design or implementation decisions.

**Primary Responsibilities:**

- Parse the Tech Challenge requirements.
- Eliminate ambiguity.
- Define scope boundaries (in-scope / out-of-scope).
- Produce resolved assumptions as binding constraints.

**Inputs:**

- Tech Challenge PDF

**Outputs:**

- Normalized problem definition
- Explicit assumptions
- Scope lock (PoC boundaries)

**Why this GPT exists:**

This agent prevents all downstream GPTs from making implicit assumptions or inventing requirements.

---

### 4.2 GPT 2 — PRD Generator

**Objective:**

Generate a **formal Product Requirements Document (PRD)** from the normalized context.

**Primary Responsibilities:**

- Translate normalized requirements into product language.
- Define features, non-goals, and constraints.
- Establish acceptance criteria at the product level.

**Inputs:**

- Normalized context (GPT 1 output)

**Outputs:**

- PRD — Source of Truth (PDF)

**Why this GPT exists:**

Separates *problem understanding* from *solution design* and ensures product intent is explicit.

---

### 4.3 GPT 3 — User Stories Generator

**Objective:**

Convert the PRD into **explicit, testable user stories**.

**Primary Responsibilities:**

- Produce user stories with acceptance criteria.
- Define happy paths and edge cases.
- Ensure full traceability back to the PRD.

**Inputs:**

- PRD (GPT 2 output)

**Outputs:**

- User Stories — Source of Truth (PDF)

**Why this GPT exists:**

Prevents feature gaps and provides a bridge between product intent and technical execution.

---

### 4.4 GPT 4A — UX/UI Architect

**Objective:**

Define a **binding UX/UI specification** with zero visual or interaction ambiguity.

**Primary Responsibilities:**

- Define visual tokens (colors, typography).
- Define allowed UI components.
- Define screen layouts and UI states.
- Specify UX behavior for loading, empty, and error states.

**Inputs:**

- PRD
- User Stories

**Outputs:**

- UX/UI Source of Truth (PDF)

**Why this GPT exists:**

Locks the frontend experience before any code is written.

---

### 4.5 GPT 4B — Database Architect

**Objective:**

Design a **production-grade PostgreSQL schema** aligned with product and UX semantics.

**Primary Responsibilities:**

- Model persistence rules.
- Define soft deletes and deduplication.
- Ensure auditability and observability.

**Inputs:**

- PRD
- User Stories

**Outputs:**

- PostgreSQL Source of Truth (PDF)

**Why this GPT exists:**

Ensures data integrity and long-term correctness before backend logic is implemented.

---

### 4.6 GPT 5A — Tech Lead (Backend Orchestration)

**Objective:**

Define **how the system actually runs** at the backend level.

**Primary Responsibilities:**

- Define CT log polling strategy.
- Define scheduling and concurrency rules.
- Define REST API contracts.
- Classify and handle error conditions.

**Inputs:**

- PRD
- User Stories
- Database Source of Truth

**Outputs:**

- Technical Bible / Backend Source of Truth (PDF)

**Why this GPT exists:**

Bridges architecture and implementation with explicit execution rules.

---

### 4.7 GPT 5B — Infra / Frontend Architecture

**Objective:**

Define the **frontend and infrastructure architecture** needed to implement the PoC.

**Primary Responsibilities:**

- Define frontend project structure.
- Define routing and state management rules.
- Define API consumption patterns.

**Inputs:**

- UX/UI Source of Truth
- Technical Bible

**Outputs:**

- Frontend Architecture Source of Truth (PDF)

**Why this GPT exists:**

Ensures the frontend is scalable, testable, and aligned with backend contracts.

---

### 4.8 GPT 6 — Prompt Generator

**Objective:**

Generate **high-quality, execution-ready prompts** for Replit.

**Primary Responsibilities:**

- Translate all Source-of-Truth documents into prompts.
- Ensure prompts are deterministic and modular.
- Optimize prompts for AI-assisted coding.

**Inputs:**

- All previous GPT outputs

**Outputs:**

- Replit-ready prompts (Markdown / text)

**Why this GPT exists:**

Transforms design and architecture into executable AI instructions.

---

## 5. Technical Decisions and Rationale


### 5.1 Why Go for the Backend

- Required by the challenge.
- Strong concurrency model for CT polling.
- Deterministic performance.

### 5.2 Why PostgreSQL

- Required by the challenge.
- Strong relational guarantees.
- Advanced indexing (GIN, trigram).

### 5.3 Why React + TypeScript + Tailwind

- Required by the challenge.
- Fast iteration for PoC.
- Strong type safety and UI consistency.

### 5.4 Why Not Store All Certificates

- Explicitly allowed by PoC scope.
- Reduces storage and complexity.
- Focuses system on actionable signal (matches).

### 5.5 Why AI‑First Instead of Manual Design

- Faster exploration of complex design spaces.
- Forces explicit documentation.
- Reduces hidden assumptions.

Human review ensured correctness and alignment.

---

## 6. Human Validation and Ownership

All AI outputs were:

- Reviewed line‑by‑line.
- Constrained with explicit rules.
- Adjusted when misaligned with requirements.
- Fully understood and explainable by the author.

AI was used as a **multiplier**, not a replacement.

---

## 7. Known Limitations (PoC Scope)

- Single CT log only.
- No authentication.
- No real‑time streaming.
- No takedown workflows.

All limitations were **intentional** and aligned with the challenge scope.

---

## 8. Conclusion

The **AI Machine** demonstrates:

- Strong architectural thinking.
- Responsible AI usage.
- Clear communication.
- Production‑grade design under time constraints.

This approach reflects how modern engineering teams can safely and effectively integrate AI into real‑world delivery pipelines.

---

*End of document*

